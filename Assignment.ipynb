{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>youtubeId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>K26_sDKnvMU</td>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3LPANjHlPxo</td>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rEnOoWs3FuA</td>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>j9xml1CxgXI</td>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ltwvKLnj1B4</td>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25618</th>\n",
       "      <td>-oB6DN5dYWo</td>\n",
       "      <td>131252</td>\n",
       "      <td>Forklift Driver Klaus: The First Day on the Jo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25619</th>\n",
       "      <td>DK7KQ-gEdl4</td>\n",
       "      <td>131256</td>\n",
       "      <td>Feuer, Eis &amp; Dosenbier (2002)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25620</th>\n",
       "      <td>v29P-wchMZQ</td>\n",
       "      <td>131258</td>\n",
       "      <td>The Pirates (2014)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25621</th>\n",
       "      <td>dAz-nZ65jYU</td>\n",
       "      <td>131260</td>\n",
       "      <td>Rentun Ruusu (2001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25622</th>\n",
       "      <td>YWmbl_7VVYk</td>\n",
       "      <td>131262</td>\n",
       "      <td>Innocence (2014)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25623 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         youtubeId  movieId                                              title\n",
       "0      K26_sDKnvMU        1                                   Toy Story (1995)\n",
       "1      3LPANjHlPxo        2                                     Jumanji (1995)\n",
       "2      rEnOoWs3FuA        3                            Grumpier Old Men (1995)\n",
       "3      j9xml1CxgXI        4                           Waiting to Exhale (1995)\n",
       "4      ltwvKLnj1B4        5                 Father of the Bride Part II (1995)\n",
       "...            ...      ...                                                ...\n",
       "25618  -oB6DN5dYWo   131252  Forklift Driver Klaus: The First Day on the Jo...\n",
       "25619  DK7KQ-gEdl4   131256                      Feuer, Eis & Dosenbier (2002)\n",
       "25620  v29P-wchMZQ   131258                                 The Pirates (2014)\n",
       "25621  dAz-nZ65jYU   131260                                Rentun Ruusu (2001)\n",
       "25622  YWmbl_7VVYk   131262                                   Innocence (2014)\n",
       "\n",
       "[25623 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Dataset/vdoLinks.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google API.\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.http import HttpError\n",
    "\n",
    "# Displaying User Image.\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Google-Cloud-YT-Data-V3-API-Key.txt', 'r') as text_file:\n",
    "    API_KEY = text_file.read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create YouTube resource object\n",
    "myYoutube = build('youtube',\n",
    "                  'v3',\n",
    "                  developerKey=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = list()\n",
    "\n",
    "for vid in df.youtubeId:\n",
    "    try:\n",
    "        # Retrive youtube video comments\n",
    "        video_responses = myYoutube.commentThreads().list(\n",
    "            part = 'snippet, replies',\n",
    "            videoId = vid\n",
    "        ).execute()\n",
    "\n",
    "    except HttpError:\n",
    "        continue\n",
    "\n",
    "    responses.append(video_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the comments\n",
    "count = 0\n",
    "\n",
    "for video_responses in responses:\n",
    "    for item in video_responses['items']:\n",
    "        comment = item['snippet']\n",
    "        print(comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the comments\n",
    "count = 0\n",
    "\n",
    "for video_responses in responses:\n",
    "    for item in video_responses['items']:\n",
    "        count += 1\n",
    "        print(f'\\nComment - { count }:')\n",
    "        comment = item['snippet']['topLevelComment']['snippet']['textDisplay']\n",
    "        print(comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cudf'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcudf\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01masyncio\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01maiohttp\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cudf'"
     ]
    }
   ],
   "source": [
    "import cudf\n",
    "import asyncio\n",
    "import aiohttp\n",
    "from googleapiclient.discovery import build\n",
    "import json\n",
    "import time\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import matplotlib.pyplot as plt\n",
    "from dask import delayed, compute\n",
    "\n",
    "# Replace with your API key\n",
    "API_SERVICE_NAME = 'youtube'\n",
    "API_VERSION = 'v3'\n",
    "\n",
    "# Function to build YouTube API client\n",
    "def build_youtube_client():\n",
    "    return build(API_SERVICE_NAME, API_VERSION, developerKey=API_KEY)\n",
    "\n",
    "# Asynchronous function to get video details\n",
    "async def get_video_details(session, youtube, video_id):\n",
    "    try:\n",
    "        request = youtube.videos().list(\n",
    "            part=\"snippet,contentDetails,statistics\",\n",
    "            id=video_id\n",
    "        )\n",
    "        response = await session.run_in_executor(None, request.execute)\n",
    "        if response[\"items\"]:\n",
    "            return response[\"items\"][0]\n",
    "        else:\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching details for {video_id}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Asynchronous function to get comments\n",
    "async def get_comments(session, youtube, video_id):\n",
    "    comments = []\n",
    "    try:\n",
    "        request = youtube.commentThreads().list(\n",
    "            part=\"snippet\",\n",
    "            videoId=video_id,\n",
    "            maxResults=100,\n",
    "            textFormat=\"plainText\"\n",
    "        )\n",
    "        response = await session.run_in_executor(None, request.execute)\n",
    "        for item in response[\"items\"]:\n",
    "            comment = item[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"textDisplay\"]\n",
    "            comments.append(comment)\n",
    "        return comments\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching comments for {video_id}: {e}\")\n",
    "        return comments\n",
    "\n",
    "# Function to extract video data asynchronously\n",
    "async def extract_video_data(youtube, video_ids):\n",
    "    video_data = []\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = []\n",
    "        for video_id in video_ids:\n",
    "            tasks.append(asyncio.ensure_future(\n",
    "                fetch_video_data(session, youtube, video_id)\n",
    "            ))\n",
    "        video_data = await asyncio.gather(*tasks)\n",
    "    return [video for video in video_data if video]  # Filter out None results\n",
    "\n",
    "async def fetch_video_data(session, youtube, video_id):\n",
    "    video_details = await get_video_details(session, youtube, video_id)\n",
    "    if video_details:\n",
    "        comments = await get_comments(session, youtube, video_id)\n",
    "        return {\n",
    "            'video_id': video_id,\n",
    "            'title': video_details['snippet']['title'],\n",
    "            'description': video_details['snippet']['description'],\n",
    "            'view_count': int(video_details['statistics'].get('viewCount', 0)),\n",
    "            'like_count': int(video_details['statistics'].get('likeCount', 0)),\n",
    "            'dislike_count': int(video_details['statistics'].get('dislikeCount', 0)),\n",
    "            'comment_count': int(video_details['statistics'].get('commentCount', 0)),\n",
    "            'duration': video_details['contentDetails']['duration'],\n",
    "            'favorite_count': int(video_details['statistics'].get('favoriteCount', 0)),\n",
    "            'comments': comments\n",
    "        }\n",
    "\n",
    "# Function for sentiment analysis using VADER\n",
    "def analyze_sentiments(comments):\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    sentiment_scores = []\n",
    "    for comment in comments:\n",
    "        score = analyzer.polarity_scores(comment)\n",
    "        sentiment_scores.append(score['compound'])\n",
    "    return sum(sentiment_scores) / len(sentiment_scores) if sentiment_scores else 0\n",
    "\n",
    "# Function to generate the report using cuDF\n",
    "def generate_report(video_data):\n",
    "    # Convert video_data into a cuDF DataFrame\n",
    "    df = cudf.DataFrame(video_data)\n",
    "    \n",
    "    # Top-10 and bottom-10 videos based on views\n",
    "    top_10_videos = df.nlargest(10, 'view_count')\n",
    "    bottom_10_videos = df.nsmallest(10, 'view_count')\n",
    "    \n",
    "    # Most and least liked videos\n",
    "    most_liked_video = df.loc[df['like_count'].idxmax()]['title']\n",
    "    least_liked_video = df.loc[df['like_count'].idxmin()]['title']\n",
    "    \n",
    "    # Video with the highest duration\n",
    "    video_with_highest_duration = df.loc[df['duration'].idxmax()]['title']\n",
    "    \n",
    "    # Sentiment analysis using Dask\n",
    "    df['sentiment_score'] = df['comments'].apply_delayed(analyze_sentiments, meta=('sentiment_score', 'f8'))\n",
    "    df['sentiment_score'].compute()\n",
    "\n",
    "    # Top-10 videos by positive sentiment\n",
    "    top_10_positive_sentiment = df.nlargest(10, 'sentiment_score')\n",
    "    \n",
    "    # Plotting the data\n",
    "    top_10_videos['title'].to_pandas().plot(kind='barh', x='title', y='view_count', title='Top 10 Videos by View Count')\n",
    "    plt.show()\n",
    "\n",
    "    bottom_10_videos['title'].to_pandas().plot(kind='barh', x='title', y='view_count', title='Bottom 10 Videos by View Count')\n",
    "    plt.show()\n",
    "\n",
    "    top_10_positive_sentiment['title'].to_pandas().plot(kind='barh', x='title', y='sentiment_score', title='Top 10 Videos by Positive Sentiment Score')\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Most Liked Video: {most_liked_video}\")\n",
    "    print(f\"Least Liked Video: {least_liked_video}\")\n",
    "    print(f\"Video with the Highest Duration: {video_with_highest_duration}\")\n",
    "\n",
    "# Main function to run the script\n",
    "if __name__ == \"__main__\":\n",
    "    # Read video IDs from the CSV file\n",
    "    video_ids_df = cudf.read_csv('Dataset/vdoLinks.csv')\n",
    "    video_ids = video_ids_df['youtubeId'].to_pandas().tolist()\n",
    "    \n",
    "    youtube = build_youtube_client()\n",
    "    video_data = asyncio.run(extract_video_data(youtube, video_ids))\n",
    "    generate_report(video_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
